{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Assignment: Introduction to RAG Systems\n",
        "---\n",
        "\n",
        "Welcome to the first assignment in the RAG course! In this assignment, you'll build a RAG pipeline using a dataset containing news information from BBC News. The goal is to enable the LLM to retrieve relevant news details from the dataset and use that information to generate more informed responses. The model you'll be using is the [llama-3-1-8b-instruct-turbo](https://www.together.ai/models/llama-3-1), which was trained on data up to December 2023. The idea is to create a RAG system that allows it to include information on events that occurred in 2024.\n",
        "\n",
        "In this assignment, you will:\n",
        "- Use a query and retrieval function to access relevant data given a query\n",
        "- Format the data appropriately\n",
        "- Generate a prompt with the query and the relevant data to feed into the LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Table of Contents\n",
        "- [ 1 - Introduction](#1)\n",
        "  - [ 1.1 RAG architecture overview](#1-1)\n",
        "  - [ 1.2 Importing the necessary libraries](#1-2)\n",
        "- [ 2 - Loading the dataset](#2)\n",
        "- [ 3 - Main Functions](#3)\n",
        "  - [ 3.1 Query news by index function](#3-1)\n",
        "  - [ 3.2 Retrieve function](#3-2)\n",
        "  - [ 3.3 Get relevant data](#3-3)\n",
        "    - [ Exercise 1](#ex01)\n",
        "  - [ 3.4 Formatting the relevant rata](#3-4)\n",
        "    - [ Exercise 2](#ex02)\n",
        "  - [ 3.5 Generate the final prompt](#3-5)\n",
        "  - [ 3.6 LLM call](#3-6)\n",
        "- [ 4 - Experimenting with your RAG System](#4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "<h4 style=\"color:black; font-weight:bold;\">USING THE TABLE OF CONTENTS</h4>\n",
        "\n",
        "JupyterLab provides an easy way for you to navigate through your assignment. It's located under the Table of Contents tab, found in the left panel, as shown in the picture below.\n",
        "\n",
        "![TOC Location](images/toc.png)\n",
        "\n",
        "---\n",
        "\n",
        "<h4 style=\"color:green; font-weight:bold;\">TIPS FOR SUCCESSFUL GRADING OF YOUR ASSIGNMENT:</h4>\n",
        "\n",
        "- All cells are frozen except for the ones where you need to submit your solutions or when explicitly mentioned you can interact with it.\n",
        "\n",
        "- You can add new cells to experiment but these will be omitted by the grader, so don't rely on newly created cells to host your solution code, use the provided places for this.\n",
        "\n",
        "- Avoid using global variables unless you absolutely have to. The grader tests your code in an isolated environment without running all cells from the top. As a result, global variables may be unavailable when scoring your submission. Global variables that are meant to be used will be defined in UPPERCASE.\n",
        "\n",
        "- - To submit your notebook for grading, first save it by clicking the ðŸ’¾ icon on the top left of the page and then click on the <span style=\"background-color: blue; color: white; padding: 3px 5px; font-size: 16px; border-radius: 5px;\">Submit assignment</span> button on the top right of the page.\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='1'></a>\n",
        "## 1 - Introduction\n",
        "\n",
        "---\n",
        "\n",
        "<a id='1-1'></a>\n",
        "### 1.1 RAG architecture overview\n",
        "\n",
        "As presented in the lectures, a simplified diagram for RAG is as follows:\n",
        "\n",
        "<div align=\"center\">\n",
        "  <img src=\"images/rag_overview.png\" alt=\"RAG Overview\" width=\"60%\">\n",
        "</div>\n",
        "\n",
        "This assignment is designed to guide you through the general workflow. You will employ a pre-implemented retriever to obtain relevant data for a given query, format this data, and create a new prompt that includes both the query and the retrieved information. Finally, you will have the opportunity to compare the results of queries both with and without the RAG system to assess its impact on the LLM's response. \n",
        "\n",
        "Alright, let's roll up our sleeves and get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='1-2'></a>\n",
        "### 1.2 Importing the necessary libraries\n",
        "\n",
        "Run the cell below to import the necessary libraries for this assignment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "deletable": false,
        "editable": false
      },
      "outputs": [],
      "source": [
        "from utils import (\n",
        "    retrieve, \n",
        "    pprint, \n",
        "    generate_with_single_input, \n",
        "    read_dataframe, \n",
        "    display_widget\n",
        ")\n",
        "import unittests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='2'></a>\n",
        "\n",
        "<a id='2'></a>\n",
        "## 2 - Loading the dataset\n",
        "\n",
        "---\n",
        "\n",
        "In this assignment, youâ€™ll work with the Kaggle dataset [News Headlines 2024](https://www.kaggle.com/datasets/dylanjcastillo/news-headlines-2024). This dataset contains thousands of news headlines and related information from BBC News.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "deletable": false,
        "editable": false
      },
      "outputs": [],
      "source": [
        "NEWS_DATA = read_dataframe(\"news_data_dedup.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's check the data structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "deletable": false,
        "editable": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    \"guid\": \"5dae28f191cfd1047f67c409e616fc3f\",\n",
            "    \"title\": \"Paris's Moulin Rouge loses windmill sails overnight\",\n",
            "    \"description\": \"The cause of the sails' collapse from the roof of the world famous cabaret club is not yet clear.\",\n",
            "    \"venue\": \"BBC\",\n",
            "    \"url\": \"https://www.bbc.co.uk/news/world-europe-68895836\",\n",
            "    \"published_at\": \"2024-04-25\",\n",
            "    \"updated_at\": \"2024-04-26\"\n",
            "  },\n",
            "  {\n",
            "    \"guid\": \"d2c3ff79d4e068911d05416ca061cd51\",\n",
            "    \"title\": \"Ukraine uses longer-range US missiles for first time\",\n",
            "    \"description\": \"Missiles secretly delivered this month have been used to strike Russian targets in Crimea, US media say.\",\n",
            "    \"venue\": \"BBC\",\n",
            "    \"url\": \"https://www.bbc.co.uk/news/world-europe-68893196\",\n",
            "    \"published_at\": \"2024-04-25\",\n",
            "    \"updated_at\": \"2024-04-26\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "pprint(NEWS_DATA[9:11])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Important fields are `title`, `description`, `url` and `published_at`. These fields will give good information to the LLM to answer the majority of questions with good enough data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='3'></a>\n",
        "## 3 - Main Functions\n",
        "---\n",
        "Two functions will be provided to you:\n",
        "- `query_news`: Given a list of indices, this function returns all documents corresponding to those indices.\n",
        "- `retrieve`: Given a query and an integer called `top_k`, this function retrieves the `top_k` most relevant documents.\n",
        "\n",
        "The functions you will implement are:\n",
        "- `get_relevant_data`: This function takes a query and a `top_k` value and returns the `top_k` relevant documents.\n",
        "- `format_relevant_data`: Given a list of documents, this function creates a formatted string with the document information.\n",
        "\n",
        "You will then use these functions to create your own small RAG pipeline and see it in action!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='3-1'></a>\n",
        "### 3.1 Query news by index function\n",
        "\n",
        "This simple function just simplifies the return of documents given a list of indices. It is given to you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "deletable": false,
        "editable": false
      },
      "outputs": [],
      "source": [
        "def query_news(indices):\n",
        "    \"\"\"\n",
        "    Retrieves elements from a dataset based on specified indices.\n",
        "\n",
        "    Parameters:\n",
        "    indices (list of int): A list containing the indices of the desired elements in the dataset.\n",
        "    dataset (list or sequence): The dataset from which elements are to be retrieved. It should support indexing.\n",
        "\n",
        "    Returns:\n",
        "    list: A list of elements from the dataset corresponding to the indices provided in list_of_indices.\n",
        "    \"\"\"\n",
        "     \n",
        "    output = [NEWS_DATA[index] for index in indices]\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "deletable": false,
        "editable": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    \"guid\": \"e696224ac208878a5cec8bdc9f97c632\",\n",
            "    \"title\": \"Europe risks dying and faces big decisions - Macron\",\n",
            "    \"description\": \"The French president delivers a stark warning for Europe to act fast to survive in a changing world.\",\n",
            "    \"venue\": \"BBC\",\n",
            "    \"url\": \"https://www.bbc.co.uk/news/world-europe-68898887\",\n",
            "    \"published_at\": \"2024-04-25\",\n",
            "    \"updated_at\": \"2024-04-26\"\n",
            "  },\n",
            "  {\n",
            "    \"guid\": \"4f585bad8f61b715fbafe2f022ab0ae8\",\n",
            "    \"title\": \"Supreme Court divided on whether Trump has immunity\",\n",
            "    \"description\": \"The justices discussed immunity, coups, pardons, Operation Mongoose - and the future of democracy.\",\n",
            "    \"venue\": \"BBC\",\n",
            "    \"url\": \"https://www.bbc.co.uk/news/world-us-canada-68901817\",\n",
            "    \"published_at\": \"2024-04-25\",\n",
            "    \"updated_at\": \"2024-04-26\"\n",
            "  },\n",
            "  {\n",
            "    \"guid\": \"5dae28f191cfd1047f67c409e616fc3f\",\n",
            "    \"title\": \"Paris's Moulin Rouge loses windmill sails overnight\",\n",
            "    \"description\": \"The cause of the sails' collapse from the roof of the world famous cabaret club is not yet clear.\",\n",
            "    \"venue\": \"BBC\",\n",
            "    \"url\": \"https://www.bbc.co.uk/news/world-europe-68895836\",\n",
            "    \"published_at\": \"2024-04-25\",\n",
            "    \"updated_at\": \"2024-04-26\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# Fetching some indices\n",
        "indices = [3, 6, 9]\n",
        "pprint(query_news(indices))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='3-2'></a>\n",
        "### 3.2 Retrieve function\n",
        "\n",
        "The `retrieve` function is an essential part of our RAG system. While the full code is provided in the `utils.py` file, and you can examine it there, you will focus on understanding its input parameters and output for now. In Module 2, you will explore the detailed workings and various techniques for document retrieval.\n",
        "\n",
        "**Parameters:**\n",
        "- `query`: A string representing the search query for which you want to find the most relevant documents.\n",
        "- `top_k`: An integer indicating the number of top similar documents to return.\n",
        "\n",
        "**Output:**\n",
        "- The function returns a list of indices corresponding to the top `k` most similar documents from the corpus, based on their similarity scores with the query.\n",
        "\n",
        "**Call:**\n",
        "\n",
        "```Python\n",
        "retrieve(query: str, top_k: int)\n",
        "```\n",
        "\n",
        "As you move forward in this course, you'll gain deeper insights into how this function utilizes embeddings and similarity measures to perform effective document retrieval."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "deletable": false,
        "editable": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[350]\n"
          ]
        }
      ],
      "source": [
        "# Let's test the retrieve function!\n",
        "indices = retrieve(\"Concerts in North America\", top_k = 1)\n",
        "print(indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "deletable": false,
        "editable": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    \"guid\": \"927257674585bb6ef669cf2c2f409fa7\",\n",
            "    \"title\": \"\\u2018The working class can\\u2019t afford it\\u2019: the shocking truth about the money bands make on tour\",\n",
            "    \"description\": \"As Taylor Swift tops $1bn in tour revenue, musicians playing smaller venues are facing pitiful fees and frequent losses. Should the state step in to save our live music scene?When you see a band playing to thousands of fans in a sun-drenched festival field, signing a record deal with a major label or playing endlessly from the airwaves, it\\u2019s easy to conjure an image of success that comes with some serious cash to boot \\u2013 particularly when Taylor Swift has broken $1bn in revenue for her current Eras tour. But looks can be deceiving. \\u201cI don\\u2019t blame the public for seeing a band playing to 2,000 people and thinking they\\u2019re minted,\\u201d says artist manager Dan Potts. \\u201cBut the reality is quite different.\\u201dPost-Covid there has been significant focus on grassroots music venues as they struggle to stay open. There\\u2019s been less focus on the actual ability of artists to tour these venues. David Martin, chief executive officer of the Featured Artists Coalition (FAC), says we\\u2019re in a \\u201ccost-of-touring crisis\\u201d. Pretty much every cost attached to touring \\u2013 van hire, crew, travel, accommodation, food and drink \\u2013 has gone up, while fees and audiences often have not. \\u201c[Playing] live is becoming financially unsustainable for many artists,\\u201d he says. \\u201cArtists are seeing [playing] live as a loss leader now. That\\u2019s if they can even afford to make it work in the first place.\\u201d Continue reading...\",\n",
            "    \"venue\": \"The Guardian\",\n",
            "    \"url\": \"https://www.theguardian.com/music/2024/apr/25/shocking-truth-money-bands-make-on-tour-taylor-swift\",\n",
            "    \"published_at\": \"2024-04-25\",\n",
            "    \"updated_at\": \"2024-04-26\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "# Now let's query the corresponding news_\n",
        "retrieved_documents = query_news(indices)\n",
        "pprint(retrieved_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='3-3'></a>\n",
        "### 3.3 Get relevant data\n",
        "\n",
        "<a id='ex01'></a>\n",
        "### Exercise 1\n",
        "\n",
        "In this exercise, you will create a function that inputs a `query` a `top_k` and returns a list with the `relevant items`. You will consolidate the two functions described so far into only one.\n",
        "\n",
        "<details>\n",
        "<summary style=\"color: green;\">Hint 1</summary>\n",
        "The function to get the relevant indices is the <code>retrieve</code> function. Remember that it inputs a <code>query</code> and the <code>top_k</code> and returns a <b>list of indices</b>.\n",
        "</details>\n",
        "<details>\n",
        "<summary style=\"color: green;\">Hint 2</summary>\n",
        "The function to get the relevant data is the <code>query_news</code> function. It inputs a <b>set of indices</b> and outputs a list with the relevant data.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "deletable": false,
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# GRADED CELL \n",
        "\n",
        "def get_relevant_data(query: str, top_k: int = 5) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Retrieve and return the top relevant data items based on a given query.\n",
        "\n",
        "    This function performs the following steps:\n",
        "    1. Retrieves the indices of the top 'k' relevant items from a dataset based on the provided `query`.\n",
        "    2. Fetches the corresponding data for these indices from the dataset.\n",
        "\n",
        "    Parameters:\n",
        "    - query (str): The search query string used to find relevant items.\n",
        "    - top_k (int, optional): The number of top items to retrieve. Default is 5.\n",
        "\n",
        "    Returns:\n",
        "    - list[dict]: A list of dictionaries containing the data associated \n",
        "      with the top relevant items.\n",
        "\n",
        "    \"\"\"\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # Retrieve the indices of the top_k relevant items given the query\n",
        "    relevant_indices = retrieve(query, top_k)\n",
        "\n",
        "    # Obtain the data related to the items using the indices from the previous step\n",
        "    relevant_data = query_news(relevant_indices)\n",
        "\n",
        "    ### END CODE HERE\n",
        "    \n",
        "    return relevant_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "deletable": false,
        "editable": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    \"guid\": \"3ca548fe82c3fcae2c4c0c635d03eb2e\",\n",
            "    \"title\": \"Large tornado seen touching down in Nebraska\",\n",
            "    \"description\": \"Severe and powerful storms have moved across several US states, leaving many experiencing power shortages.\",\n",
            "    \"venue\": \"BBC\",\n",
            "    \"url\": \"https://www.bbc.co.uk/news/world-us-canada-68860070\",\n",
            "    \"published_at\": \"2024-04-26\",\n",
            "    \"updated_at\": \"2024-04-28\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "query = \"Greatest storms in the US\"\n",
        "relevant_data = get_relevant_data(query, top_k = 1)\n",
        "pprint(relevant_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Expected output**\n",
        "```\n",
        "[{'guid': '3ca548fe82c3fcae2c4c0c635d03eb2e',\n",
        "  'title': 'Large tornado seen touching down in Nebraska',\n",
        "  'description': 'Severe and powerful storms have moved across several US '\n",
        "                 'states, leaving many experiencing power shortages.',\n",
        "  'venue': 'BBC',\n",
        "  'url': 'https://www.bbc.co.uk/news/world-us-canada-68860070',\n",
        "  'published_at': '2024-04-26',\n",
        "  'updated_at': '2024-04-28'}]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "deletable": false,
        "editable": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92m All tests passed!\n"
          ]
        }
      ],
      "source": [
        "# Run this cell to perform several tests on your function. If you receive \"All test passed!\" it means that your solution will likely pass the autograder too.\n",
        "unittests.test_get_relevant_data(get_relevant_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='3-4'></a>\n",
        "\n",
        "<a id='3-4'></a>\n",
        "### 3.4 Formatting the relevant rata\n",
        "\n",
        "\n",
        "<a id='ex02'></a>\n",
        "\n",
        "<a id='ex02'></a>\n",
        "### Exercise 2\n",
        "\n",
        "In this exercise, you will create the `format_relevant_data` function that takes a list of data and formats it.\n",
        "\n",
        "**Note:** You can adjust the layout, but your output **must** include these pieces of information:\n",
        "\n",
        "* News title\n",
        "* News description\n",
        "* News published date\n",
        "* News URL\n",
        "\n",
        "You must include the exact keywords `'title'`, `'url'`, `'published'`, and `'description'` somewhere in your output (uppercase or lowercase versions are fine). These are required for grading.\n",
        "\n",
        "**Tip:** Itâ€™s recommended to use **double quotes** for strings and **single quotes** for dictionary keys (for example, `data['title']`).\n",
        "Hereâ€™s one way you could format it:\n",
        "\n",
        "```python\n",
        "f\"\"\"\n",
        "Title: {news_1_title}, Description: {news_1_description}, Published at: {news_1_published_date}\\nURL: {news_1_URL}\n",
        "Title: {news_2_title}, Description: {news_2_description}, Published at: {news_2_published_date}\\nURL: {news_2_URL}\n",
        "...\n",
        "Title: {news_k_title}, Description: {news_k_description}, Published at: {news_k_published_date}\\nURL: {news_k_URL}\n",
        "\"\"\"\n",
        "```\n",
        "\n",
        "<details>  \n",
        "<summary style=\"color: green;\">Hint 1</summary>  \n",
        "<p>You can access each property of a document using its key in the dictionary.</p>  \n",
        "<p>For example, to get the title: <code>document['title']</code></p>  \n",
        "<p>You can format it like this: <code>f\"Title: {document['title']}\"</code></p>  \n",
        "</details>\n",
        "\n",
        "<details>  \n",
        "<summary style=\"color: green;\">Hint 2</summary>  \n",
        "<p>Remember to append each formatted document to the <code>formatted_documents</code> list by doing <code>formatted_documents.append(formatted_document)</code>.</p>  \n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "deletable": false,
        "editable": true,
        "tags": [
          "graded"
        ]
      },
      "outputs": [],
      "source": [
        "# GRADED CELL\n",
        "\n",
        "def format_relevant_data(relevant_data):\n",
        "    \"\"\"\n",
        "    Retrieves the top_k most relevant documents based on a given query and constructs an augmented prompt for a RAG system.\n",
        "\n",
        "    Parameters:\n",
        "    relevant_data (list): A list with relevant data.\n",
        "\n",
        "    Returns:\n",
        "    str: An augmented prompt with the top_k relevant documents, formatted for use in a Retrieval-Augmented Generation (RAG) system.\"\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # Create a list so store the formatted documents\n",
        "    formatted_documents = []\n",
        "    \n",
        "    # Iterates over each relevant document.\n",
        "    for document in relevant_data:\n",
        "\n",
        "        # Formats each document into a structured layout string. Remember that each document is in one different line. So you should add a new line character after each document added.\n",
        "        formatted_document = (\n",
        "            f\"Title: {document['title']}, \"\n",
        "            f\"Description: {document['description']}, \"\n",
        "            f\"Published at: {document['published_at']}, \"\n",
        "            f\"URL: {document['url']}\"\n",
        "        )\n",
        "        \n",
        "        # Append the formatted document string to the formatted_documents list\n",
        "        formatted_documents.append(formatted_document)\n",
        "    \n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Returns the final augmented prompt string.\n",
        "\n",
        "    return \"\\n\".join(formatted_documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "deletable": false,
        "editable": false
      },
      "outputs": [],
      "source": [
        "example_data = NEWS_DATA[4:8]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's test your function with some queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "deletable": false,
        "editable": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Title: Prosecutors ask for halt to case against Spain PM's wife, Description: Pedro SÃ¡nchez is deciding whether to resign after a case against his wife by an anti-corruption group., Published at: 2024-04-25, URL: https://www.bbc.co.uk/news/world-europe-68895727\n",
            "Title: WATCH: Would you pay a tourist fee to enter Venice?, Description: From Thursday visitors making a trip to the famous city at peak times will be charged a trial entrance fee., Published at: 2024-04-25, URL: https://www.bbc.co.uk/news/world-europe-68898441\n",
            "Title: Supreme Court divided on whether Trump has immunity, Description: The justices discussed immunity, coups, pardons, Operation Mongoose - and the future of democracy., Published at: 2024-04-25, URL: https://www.bbc.co.uk/news/world-us-canada-68901817\n",
            "Title: More than 150 killed as heavy rains pound Tanzania, Description: The prime minister warns that El NiÃ±o-triggered heavy rains are likely to continue into May., Published at: 2024-04-25, URL: https://www.bbc.co.uk/news/world-africa-68896454\n"
          ]
        }
      ],
      "source": [
        "print(format_relevant_data(example_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "deletable": false,
        "editable": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92m All tests passed!\n"
          ]
        }
      ],
      "source": [
        "# Test your function!\n",
        "unittests.test_format_relevant_data(format_relevant_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='3-5'></a>\n",
        "### 3.5 Generate the final prompt\n",
        "\n",
        "The next function is given to you. It will generate the final prompt, integrating it with the query. Feel free to change the prompt and experiment how different prompts impact the final result!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "deletable": false,
        "editable": true,
        "tags": []
      },
      "outputs": [],
      "source": [
        "# EDITABLE CELL\n",
        "\n",
        "def generate_final_prompt(query, top_k=5, use_rag=True, prompt=None):\n",
        "    \"\"\"\n",
        "    Generates a final prompt based on a user query, optionally incorporating relevant data using retrieval-augmented generation (RAG).\n",
        "\n",
        "    Args:\n",
        "        query (str): The user query for which the prompt is to be generated.\n",
        "        top_k (int, optional): The number of top relevant data pieces to retrieve and incorporate. Default is 5.\n",
        "        use_rag (bool, optional): A flag indicating whether to use retrieval-augmented generation (RAG)\n",
        "                                  by including relevant data in the prompt. Default is True.\n",
        "        prompt (str, optional): A template string for the prompt. It can contain placeholders {query} and {documents}\n",
        "                                for formatting with the query and formatted relevant data, respectively.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated prompt, either consisting solely of the query or expanded with relevant data\n",
        "             formatted for additional context.\n",
        "    \"\"\"\n",
        "    # If RAG is not being used, format the prompt with just the query or return the query directly\n",
        "    if not use_rag:\n",
        "        return query\n",
        "\n",
        "    # Retrieve the top_k relevant data pieces based on the query\n",
        "    relevant_data = get_relevant_data(query, top_k=1)\n",
        "\n",
        "    # Format the retrieved relevant data\n",
        "    retrieve_data_formatted = format_relevant_data(relevant_data)\n",
        "\n",
        "    # If no custom prompt is provided, use the default prompt template\n",
        "    if prompt is None:\n",
        "        prompt = (\n",
        "            f\"Answer the user query below. There will be provided additional information for you to compose your answer. \"\n",
        "            f\"The relevant information provided is from 2024 and it should be added as your overall knowledge to answer the query, \"\n",
        "            f\"you should not rely only on this information to answer the query, but add it to your overall knowledge.\"\n",
        "            f\"Query: {query}\\n\"\n",
        "            f\"2024 News: {retrieve_data_formatted}\"\n",
        "        )\n",
        "    else:\n",
        "        # If a custom prompt is provided, format it with the query and formatted relevant data\n",
        "        prompt = prompt.format(query=query, documents=retrieve_data_formatted)\n",
        "\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "deletable": false,
        "editable": false,
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer the user query below. There will be provided additional information for you to compose your answer. The relevant information provided is from 2024 and it should be added as your overall knowledge to answer the query, you should not rely only on this information to answer the query, but add it to your overall knowledge.Query: Tell me about the US GDP in the past 3 years.\n",
            "2024 News: Title: America's Economy Is No. 1. That Means Trouble, Description: If you want a single number to capture Americaâ€™s economic stature, here it is: This year, the U.S. will account for 26.3% of the global gross domestic product, the highest in almost two decades. Thatâ€™s based on the latest projections from the International Monetary Fund. According to the IMF, Europeâ€™s share of world GDP has dropped 1.4 percentage points since 2018, and Japanâ€™s by 2.1 points. The U.S. share, by contrast, is up 2.3 points., Published at: 2024-04-26, URL: https://www.wsj.com/articles/americas-economy-is-no-1-that-means-trouble-d008e4bd\n"
          ]
        }
      ],
      "source": [
        "print(generate_final_prompt(\"Tell me about the US GDP in the past 3 years.\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='3-6'></a>\n",
        "### 3.6 LLM call\n",
        "\n",
        "Now let's integrate the function above to feed an LLM. Its parameters are:\n",
        "\n",
        "- `query`: the query to be passed to the LLM.\n",
        "- `use_rag`: a boolean telling whether using RAG or not. This parameter will help you compare queries using a RAG system and not using it.\n",
        "- `model`: the model to be used. You might change it, but the standard is the Llama 3 Billion parameter.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "deletable": false,
        "editable": false,
        "tags": []
      },
      "outputs": [],
      "source": [
        "def llm_call(query, top_k = 5, use_rag = True, prompt = None):\n",
        "    \"\"\"\n",
        "    Calls the LLM to generate a response based on a query, optionally using retrieval-augmented generation.\n",
        "\n",
        "    Args:\n",
        "        query (str): The user query that will be processed by the language model.\n",
        "        use_rag (bool, optional): A flag that indicates whether to use retrieval-augmented generation by \n",
        "                                  incorporating relevant documents into the prompt. Default is True.\n",
        "\n",
        "    Returns:\n",
        "        str: The content of the response generated by the language model.\n",
        "    \"\"\"\n",
        "    \n",
        "\n",
        "    # Get the prompt with the query + relevant documents\n",
        "    prompt = generate_final_prompt(query, top_k, use_rag, prompt)\n",
        "\n",
        "    # Call the LLM\n",
        "    generated_response = generate_with_single_input(prompt)\n",
        "\n",
        "    # Get the content\n",
        "    generated_message = generated_response['content']\n",
        "    \n",
        "    return generated_message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "deletable": false,
        "editable": false,
        "tags": []
      },
      "outputs": [],
      "source": [
        "query = \"Tell me about the US GDP in the past 3 years.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "deletable": false,
        "editable": false,
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Huzaifa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'proxy.dlai.link'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "Exception",
          "evalue": "Error while calling LLM: f<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n<HTML><HEAD><META HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html; charset=iso-8859-1\">\n<TITLE>ERROR: The request could not be satisfied</TITLE>\n</HEAD><BODY>\n<H1>403 ERROR</H1>\n<H2>The request could not be satisfied.</H2>\n<HR noshade size=\"1px\">\nRequest blocked.\nWe can't connect to the server for this app or website at this time. There might be too much traffic or a configuration error. Try again later, or contact the app or website owner.\n<BR clear=\"all\">\nIf you provide content to customers through CloudFront, you can find steps to troubleshoot and help prevent this error by reviewing the CloudFront documentation.\n<BR clear=\"all\">\n<HR noshade size=\"1px\">\n<PRE>\nGenerated by cloudfront (CloudFront)\nRequest ID: RI468OhGQF3vIDu9dzE_19QwdtWyAs9NbVJ9ps9gLWLZaWEaPAhAig==\n</PRE>\n<ADDRESS>\n</ADDRESS>\n</BODY></HTML>",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[51], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mllm_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_rag\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n",
            "Cell \u001b[1;32mIn[49], line 19\u001b[0m, in \u001b[0;36mllm_call\u001b[1;34m(query, top_k, use_rag, prompt)\u001b[0m\n\u001b[0;32m     16\u001b[0m prompt \u001b[38;5;241m=\u001b[39m generate_final_prompt(query, top_k, use_rag, prompt)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Call the LLM\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m generated_response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_with_single_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Get the content\u001b[39;00m\n\u001b[0;32m     22\u001b[0m generated_message \u001b[38;5;241m=\u001b[39m generated_response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[1;32mu:\\RAG\\RAG1\\utils.py:69\u001b[0m, in \u001b[0;36mgenerate_with_single_input\u001b[1;34m(prompt, role, top_p, temperature, max_tokens, model, together_api_key, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(url, json \u001b[38;5;241m=\u001b[39m payload, verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response\u001b[38;5;241m.\u001b[39mok:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while calling LLM: f\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     json_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext)\n",
            "\u001b[1;31mException\u001b[0m: Error while calling LLM: f<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n<HTML><HEAD><META HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html; charset=iso-8859-1\">\n<TITLE>ERROR: The request could not be satisfied</TITLE>\n</HEAD><BODY>\n<H1>403 ERROR</H1>\n<H2>The request could not be satisfied.</H2>\n<HR noshade size=\"1px\">\nRequest blocked.\nWe can't connect to the server for this app or website at this time. There might be too much traffic or a configuration error. Try again later, or contact the app or website owner.\n<BR clear=\"all\">\nIf you provide content to customers through CloudFront, you can find steps to troubleshoot and help prevent this error by reviewing the CloudFront documentation.\n<BR clear=\"all\">\n<HR noshade size=\"1px\">\n<PRE>\nGenerated by cloudfront (CloudFront)\nRequest ID: RI468OhGQF3vIDu9dzE_19QwdtWyAs9NbVJ9ps9gLWLZaWEaPAhAig==\n</PRE>\n<ADDRESS>\n</ADDRESS>\n</BODY></HTML>"
          ]
        }
      ],
      "source": [
        "print(llm_call(query, use_rag = True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "deletable": false,
        "editable": false,
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Huzaifa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'proxy.dlai.link'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "Exception",
          "evalue": "Error while calling LLM: f<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n<HTML><HEAD><META HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html; charset=iso-8859-1\">\n<TITLE>ERROR: The request could not be satisfied</TITLE>\n</HEAD><BODY>\n<H1>403 ERROR</H1>\n<H2>The request could not be satisfied.</H2>\n<HR noshade size=\"1px\">\nRequest blocked.\nWe can't connect to the server for this app or website at this time. There might be too much traffic or a configuration error. Try again later, or contact the app or website owner.\n<BR clear=\"all\">\nIf you provide content to customers through CloudFront, you can find steps to troubleshoot and help prevent this error by reviewing the CloudFront documentation.\n<BR clear=\"all\">\n<HR noshade size=\"1px\">\n<PRE>\nGenerated by cloudfront (CloudFront)\nRequest ID: de9vZmFH8kahvWC4YGbR4PyEXj-PLelWinhhVObkZnwL2oEHEOxAGQ==\n</PRE>\n<ADDRESS>\n</ADDRESS>\n</BODY></HTML>",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mllm_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_rag\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m)\n",
            "Cell \u001b[1;32mIn[34], line 19\u001b[0m, in \u001b[0;36mllm_call\u001b[1;34m(query, top_k, use_rag, prompt)\u001b[0m\n\u001b[0;32m     16\u001b[0m prompt \u001b[38;5;241m=\u001b[39m generate_final_prompt(query, top_k, use_rag, prompt)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Call the LLM\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m generated_response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_with_single_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Get the content\u001b[39;00m\n\u001b[0;32m     22\u001b[0m generated_message \u001b[38;5;241m=\u001b[39m generated_response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
            "File \u001b[1;32mu:\\RAG\\RAG1\\utils.py:69\u001b[0m, in \u001b[0;36mgenerate_with_single_input\u001b[1;34m(prompt, role, top_p, temperature, max_tokens, model, together_api_key, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(url, json \u001b[38;5;241m=\u001b[39m payload, verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response\u001b[38;5;241m.\u001b[39mok:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while calling LLM: f\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     json_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mtext)\n",
            "\u001b[1;31mException\u001b[0m: Error while calling LLM: f<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\" \"http://www.w3.org/TR/html4/loose.dtd\">\n<HTML><HEAD><META HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html; charset=iso-8859-1\">\n<TITLE>ERROR: The request could not be satisfied</TITLE>\n</HEAD><BODY>\n<H1>403 ERROR</H1>\n<H2>The request could not be satisfied.</H2>\n<HR noshade size=\"1px\">\nRequest blocked.\nWe can't connect to the server for this app or website at this time. There might be too much traffic or a configuration error. Try again later, or contact the app or website owner.\n<BR clear=\"all\">\nIf you provide content to customers through CloudFront, you can find steps to troubleshoot and help prevent this error by reviewing the CloudFront documentation.\n<BR clear=\"all\">\n<HR noshade size=\"1px\">\n<PRE>\nGenerated by cloudfront (CloudFront)\nRequest ID: de9vZmFH8kahvWC4YGbR4PyEXj-PLelWinhhVObkZnwL2oEHEOxAGQ==\n</PRE>\n<ADDRESS>\n</ADDRESS>\n</BODY></HTML>"
          ]
        }
      ],
      "source": [
        "print(llm_call(query, use_rag = False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id='4'></a>\n",
        "\n",
        "<a id='4'></a>\n",
        "## 4 - Experimenting with your RAG System\n",
        "---\n",
        "\n",
        "Now you can experiment with your own queries to see the system in action! You can write any query, and it will display answers both with and without RAG. Keep in mind that the dataset you're working with is related to news data from 2024, so not all queries will be effective in demonstrating the framework. Some example queries you might try include:\n",
        "\n",
        "* What were the most important events of the past year?\n",
        "* How is global warming progressing in 2024?\n",
        "* Tell me about the most recent advances in AI.\n",
        "* Give me the most important facts from past year.\n",
        "\n",
        "You can also specify a layout for the augmented prompt that includes placeholders for {query} and {documents} to indicate where they should be inserted within your prompt structure. For example:\n",
        "\n",
        "```\n",
        "This is the query: {query}\n",
        "These are the documents: {documents}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "deletable": false,
        "editable": false,
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "205a21ce76d54d3196477e7cea665ad1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HTML(value='\\n    <style>\\n        .custom-output {\\n            background-color: #f9f9f9;\\n            colorâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b39aff697324d37b0f11e7fdd3a7589",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Text(value='', description='Query:', layout=Layout(width='100%'), placeholder='Type your query here')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "893102f6566347e5b963b881c6b4b100",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Textarea(value='', description='Augmented prompt layout:', layout=Layout(height='100px', width='100%'), placehâ€¦"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c6f0d692503e426ca07ef7b1f9dfc91d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "IntSlider(value=5, description='Top K:', max=20, min=1, style=SliderStyle(description_width='initial'))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5b9a1c1fe1140018b82e6794ac4f6f4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Button(description='Get Responses', style=ButtonStyle(button_color='#f0f0f0'))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9bfbae467a62441386ec1d50c7aeb574",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display_widget(llm_call)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Congratulations! You created your first simple RAG system! Keep it up!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
